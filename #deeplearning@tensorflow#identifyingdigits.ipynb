{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shikhar2402/MACHINE-LEARNING-FOR-BEGINNERS/blob/master/%23deeplearning%40tensorflow%23identifyingdigits.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8HAWsp0c2-PD",
        "colab_type": "code",
        "outputId": "bc6499d3-9bf0-4b69-916e-0ce0744df0f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 370
        }
      },
      "source": [
        "\n",
        "import tensorflow as tf  # deep learning library. Tensors are just multi-dimensional arrays\n",
        "\n",
        "mnist = tf.keras.datasets.mnist  # mnist is a dataset of 28x28 images of handwritten digits and their labels\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()  # unpacks images to x_train/x_test and labels to y_train/y_test\n",
        "\n",
        "x_train = tf.keras.utils.normalize(x_train, axis=1)  # scales data between 0 and 1\n",
        "x_test = tf.keras.utils.normalize(x_test, axis=1)  # scales data between 0 and 1\n",
        "\n",
        "model = tf.keras.models.Sequential()  # a basic feed-forward model\n",
        "model.add(tf.keras.layers.Flatten())  # takes our 28x28 and makes it 1x784\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "model.add(tf.keras.layers.Dense(128, activation=tf.nn.relu))  # a simple fully-connected layer, 128 units, relu activation\n",
        "model.add(tf.keras.layers.Dense(10, activation=tf.nn.softmax))  # our output layer. 10 units for 10 classes. Softmax for probability distribution\n",
        "\n",
        "model.compile(optimizer='adam',  # Good default optimizer to start with\n",
        "              loss='sparse_categorical_crossentropy',  # how will we calculate our \"error.\" Neural network aims to minimize loss.\n",
        "              metrics=['accuracy'])  # what to track\n",
        "\n",
        "model.fit(x_train, y_train, epochs=10)# train the model\n"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "60000/60000 [==============================] - 5s 80us/sample - loss: 0.2583 - acc: 0.9252\n",
            "Epoch 2/10\n",
            "60000/60000 [==============================] - 5s 79us/sample - loss: 0.1045 - acc: 0.9675\n",
            "Epoch 3/10\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0705 - acc: 0.9780\n",
            "Epoch 4/10\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0513 - acc: 0.9839\n",
            "Epoch 5/10\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0408 - acc: 0.9869\n",
            "Epoch 6/10\n",
            "60000/60000 [==============================] - 4s 73us/sample - loss: 0.0310 - acc: 0.9895\n",
            "Epoch 7/10\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0243 - acc: 0.9915\n",
            "Epoch 8/10\n",
            "60000/60000 [==============================] - 4s 75us/sample - loss: 0.0207 - acc: 0.9930\n",
            "Epoch 9/10\n",
            "60000/60000 [==============================] - 5s 75us/sample - loss: 0.0183 - acc: 0.9936\n",
            "Epoch 10/10\n",
            "60000/60000 [==============================] - 4s 74us/sample - loss: 0.0145 - acc: 0.9952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f01f5558518>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VoHbN_qm8I_K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "5a987d71-d1fa-46b6-ddaa-6c03fe911a2e"
      },
      "source": [
        "val_loss, val_acc = model.evaluate(x_test, y_test)  # evaluate the out of sample data with model\n",
        "print(val_loss)  # model's loss (error)\n",
        "print(val_acc)  \n",
        "print(y_train[2])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "10000/10000 [==============================] - 0s 35us/sample - loss: 0.1278 - acc: 0.9726\n",
            "0.1277587116169445\n",
            "0.9726\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nNCKXcag_Hr6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "e7291700-88dc-4be5-e8fd-a51826913c67"
      },
      "source": [
        "model.save('epic_num_reader.model')\n",
        "\n",
        "\n",
        "new_model = tf.keras.models.load_model('epic_num_reader.model')\n",
        "\n",
        "predictions = new_model.predict(x_test)\n",
        "print(predictions)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0615 21:15:02.876938 139647391098752 hdf5_format.py:263] Sequential models without an `input_shape` passed to the first layer cannot reload their optimizer state. As a result, your model isstarting with a freshly initialized optimizer.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[[3.16764437e-14 6.15002754e-12 5.52047019e-11 ... 9.99999166e-01\n",
            "  9.96852882e-13 1.22170815e-11]\n",
            " [1.55657628e-18 1.10096325e-05 9.99989033e-01 ... 3.91732477e-14\n",
            "  2.66549738e-12 1.51566872e-21]\n",
            " [7.94392763e-13 1.00000000e+00 3.14312243e-10 ... 3.77552922e-08\n",
            "  2.26710171e-08 2.46636739e-11]\n",
            " ...\n",
            " [3.92355835e-18 8.08041856e-10 3.48229459e-16 ... 1.81294063e-10\n",
            "  3.87233232e-11 2.22868692e-07]\n",
            " [1.88075944e-12 3.23022276e-10 3.85265279e-13 ... 4.28987779e-09\n",
            "  1.12276815e-04 2.99318521e-16]\n",
            " [1.01791076e-10 1.38223072e-10 1.31119074e-10 ... 1.47994916e-19\n",
            "  2.91674150e-11 4.70311859e-14]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_0DVSKMJ_S1E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 286
        },
        "outputId": "19b9a41f-34e8-4e10-b0a1-19afca61909f"
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "print(np.argmax(predictions[0]))\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.imshow(x_test[0],cmap=plt.cm.binary)\n",
        "plt.show()"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "7\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}